{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3316532,"sourceType":"datasetVersion","datasetId":10100}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from gensim.test.utils import datapath\nfrom gensim.models import FastText\nimport pandas as pd\nimport nltk\nfrom gensim.parsing.preprocessing import STOPWORDS\nimport re\nnltk.download('stopwords') \nnltk.download('wordnet') ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-16T03:45:20.227888Z","iopub.execute_input":"2024-04-16T03:45:20.228720Z","iopub.status.idle":"2024-04-16T03:45:35.916303Z","shell.execute_reply.started":"2024-04-16T03:45:20.228682Z","shell.execute_reply":"2024-04-16T03:45:35.915451Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"STOPWORDS","metadata":{"execution":{"iopub.status.busy":"2024-04-16T03:45:35.917960Z","iopub.execute_input":"2024-04-16T03:45:35.918476Z","iopub.status.idle":"2024-04-16T03:45:35.930053Z","shell.execute_reply.started":"2024-04-16T03:45:35.918450Z","shell.execute_reply":"2024-04-16T03:45:35.929185Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"frozenset({'a',\n           'about',\n           'above',\n           'across',\n           'after',\n           'afterwards',\n           'again',\n           'against',\n           'all',\n           'almost',\n           'alone',\n           'along',\n           'already',\n           'also',\n           'although',\n           'always',\n           'am',\n           'among',\n           'amongst',\n           'amoungst',\n           'amount',\n           'an',\n           'and',\n           'another',\n           'any',\n           'anyhow',\n           'anyone',\n           'anything',\n           'anyway',\n           'anywhere',\n           'are',\n           'around',\n           'as',\n           'at',\n           'back',\n           'be',\n           'became',\n           'because',\n           'become',\n           'becomes',\n           'becoming',\n           'been',\n           'before',\n           'beforehand',\n           'behind',\n           'being',\n           'below',\n           'beside',\n           'besides',\n           'between',\n           'beyond',\n           'bill',\n           'both',\n           'bottom',\n           'but',\n           'by',\n           'call',\n           'can',\n           'cannot',\n           'cant',\n           'co',\n           'computer',\n           'con',\n           'could',\n           'couldnt',\n           'cry',\n           'de',\n           'describe',\n           'detail',\n           'did',\n           'didn',\n           'do',\n           'does',\n           'doesn',\n           'doing',\n           'don',\n           'done',\n           'down',\n           'due',\n           'during',\n           'each',\n           'eg',\n           'eight',\n           'either',\n           'eleven',\n           'else',\n           'elsewhere',\n           'empty',\n           'enough',\n           'etc',\n           'even',\n           'ever',\n           'every',\n           'everyone',\n           'everything',\n           'everywhere',\n           'except',\n           'few',\n           'fifteen',\n           'fifty',\n           'fill',\n           'find',\n           'fire',\n           'first',\n           'five',\n           'for',\n           'former',\n           'formerly',\n           'forty',\n           'found',\n           'four',\n           'from',\n           'front',\n           'full',\n           'further',\n           'get',\n           'give',\n           'go',\n           'had',\n           'has',\n           'hasnt',\n           'have',\n           'he',\n           'hence',\n           'her',\n           'here',\n           'hereafter',\n           'hereby',\n           'herein',\n           'hereupon',\n           'hers',\n           'herself',\n           'him',\n           'himself',\n           'his',\n           'how',\n           'however',\n           'hundred',\n           'i',\n           'ie',\n           'if',\n           'in',\n           'inc',\n           'indeed',\n           'interest',\n           'into',\n           'is',\n           'it',\n           'its',\n           'itself',\n           'just',\n           'keep',\n           'kg',\n           'km',\n           'last',\n           'latter',\n           'latterly',\n           'least',\n           'less',\n           'ltd',\n           'made',\n           'make',\n           'many',\n           'may',\n           'me',\n           'meanwhile',\n           'might',\n           'mill',\n           'mine',\n           'more',\n           'moreover',\n           'most',\n           'mostly',\n           'move',\n           'much',\n           'must',\n           'my',\n           'myself',\n           'name',\n           'namely',\n           'neither',\n           'never',\n           'nevertheless',\n           'next',\n           'nine',\n           'no',\n           'nobody',\n           'none',\n           'noone',\n           'nor',\n           'not',\n           'nothing',\n           'now',\n           'nowhere',\n           'of',\n           'off',\n           'often',\n           'on',\n           'once',\n           'one',\n           'only',\n           'onto',\n           'or',\n           'other',\n           'others',\n           'otherwise',\n           'our',\n           'ours',\n           'ourselves',\n           'out',\n           'over',\n           'own',\n           'part',\n           'per',\n           'perhaps',\n           'please',\n           'put',\n           'quite',\n           'rather',\n           're',\n           'really',\n           'regarding',\n           'same',\n           'say',\n           'see',\n           'seem',\n           'seemed',\n           'seeming',\n           'seems',\n           'serious',\n           'several',\n           'she',\n           'should',\n           'show',\n           'side',\n           'since',\n           'sincere',\n           'six',\n           'sixty',\n           'so',\n           'some',\n           'somehow',\n           'someone',\n           'something',\n           'sometime',\n           'sometimes',\n           'somewhere',\n           'still',\n           'such',\n           'system',\n           'take',\n           'ten',\n           'than',\n           'that',\n           'the',\n           'their',\n           'them',\n           'themselves',\n           'then',\n           'thence',\n           'there',\n           'thereafter',\n           'thereby',\n           'therefore',\n           'therein',\n           'thereupon',\n           'these',\n           'they',\n           'thick',\n           'thin',\n           'third',\n           'this',\n           'those',\n           'though',\n           'three',\n           'through',\n           'throughout',\n           'thru',\n           'thus',\n           'to',\n           'together',\n           'too',\n           'top',\n           'toward',\n           'towards',\n           'twelve',\n           'twenty',\n           'two',\n           'un',\n           'under',\n           'unless',\n           'until',\n           'up',\n           'upon',\n           'us',\n           'used',\n           'using',\n           'various',\n           'very',\n           'via',\n           'was',\n           'we',\n           'well',\n           'were',\n           'what',\n           'whatever',\n           'when',\n           'whence',\n           'whenever',\n           'where',\n           'whereafter',\n           'whereas',\n           'whereby',\n           'wherein',\n           'whereupon',\n           'wherever',\n           'whether',\n           'which',\n           'while',\n           'whither',\n           'who',\n           'whoever',\n           'whole',\n           'whom',\n           'whose',\n           'why',\n           'will',\n           'with',\n           'within',\n           'without',\n           'would',\n           'yet',\n           'you',\n           'your',\n           'yours',\n           'yourself',\n           'yourselves'})"},"metadata":{}}]},{"cell_type":"code","source":"data_tip=pd.read_json('/kaggle/input/yelp-dataset/yelp_academic_dataset_tip.json', lines=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T03:45:35.931520Z","iopub.execute_input":"2024-04-16T03:45:35.931795Z","iopub.status.idle":"2024-04-16T03:45:44.380947Z","shell.execute_reply.started":"2024-04-16T03:45:35.931743Z","shell.execute_reply":"2024-04-16T03:45:44.379915Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\ntip_text = data_tip['text']","metadata":{"execution":{"iopub.status.busy":"2024-04-16T03:45:44.383142Z","iopub.execute_input":"2024-04-16T03:45:44.383429Z","iopub.status.idle":"2024-04-16T03:45:44.387671Z","shell.execute_reply.started":"2024-04-16T03:45:44.383405Z","shell.execute_reply":"2024-04-16T03:45:44.386828Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"tip_text[:3]","metadata":{"execution":{"iopub.status.busy":"2024-04-16T03:45:44.389067Z","iopub.execute_input":"2024-04-16T03:45:44.389552Z","iopub.status.idle":"2024-04-16T03:45:44.400019Z","shell.execute_reply.started":"2024-04-16T03:45:44.389522Z","shell.execute_reply":"2024-04-16T03:45:44.399118Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"0                       Avengers time with the ladies.\n1    They have lots of good deserts and tasty cuban...\n2               It's open even when you think it isn't\nName: text, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"!python -m nltk.downloader -d /usr/local/share/nltk_data all","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import spacy\n\ndef process_text(document,stopwords=STOPWORDS):\n    nlp = spacy.load(\"en_core_web_sm\")\n    document = re.sub(r'\\s+', ' ', document, flags=re.I) \n    document = re.sub(r'\\W', ' ', str(document)) \n    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document) \n    document = document.lower() \n    tokens = document.split()\n    doc_spacy=nlp(document)\n    \n    lemma_txt = [\"\".join(token.lemma_) for token in doc_spacy]\n    lemma_no_stop_txt = [word for word in lemma_txt if word not in STOPWORDS]\n    tokens = [word for word in tokens if len(word) > 3]\n    clean_txt = ' '.join(lemma_no_stop_txt)\n    return clean_txt\n\ntip_text_preprocessed = tip_text.apply(process_text)\n\nmodel3 = FastText(vector_size=4, workers=7, window=7, min_count=1)\nmodel3.build_vocab(corpus_iterable=tip_text_preprocessed)\ntotal_words = model3.corpus_total_words\nmodel3.train(corpus_iterable=tip_text_preprocessed, total_words=total_words, epochs=5)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T03:46:23.793032Z","iopub.execute_input":"2024-04-16T03:46:23.793327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cupy as cp\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Load stopwords (if not already loaded)\nSTOPWORDS = spacy.lang.en.stop_words.STOP_WORDS\n\ndef process_text(document, stopwords=STOPWORDS):\n    # Regular expression preprocessing\n    document = re.sub(r'\\s+', ' ', document, flags=re.I) \n    document = re.sub(r'\\W', ' ', str(document)) \n    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document) \n    document = document.lower() \n    \n    # Tokenization using SpaCy\n    doc_spacy = nlp(document)\n    \n    # Lemmatization and stopword removal\n    lemma_no_stop_txt = [token.lemma_ for token in doc_spacy if token.lemma_ not in stopwords]\n    \n    # Filtering tokens based on length\n    tokens = [word for word in lemma_no_stop_txt if len(word) > 3]\n    \n    # Joining tokens into a clean text\n    clean_txt = ' '.join(tokens)\n    return clean_txt\n\n# Assuming tip_text is a pandas Series containing the text data\ntip_text_preprocessed = tip_text.apply(process_text)\n\n# Transfer data to GPU\ntip_text_preprocessed_gpu = cp.asarray(tip_text_preprocessed)\n\n# Initialize FastText model with GPU support\nmodel3 = FastText(vector_size=4, workers=7, window=7, min_count=1)\n\n# Build vocabulary on GPU\nmodel3.build_vocab(corpus_iterable=tip_text_preprocessed_gpu)\n\n# Train FastText model on GPU\ntotal_words = model3.corpus_total_words\nmodel3.train(corpus_iterable=tip_text_preprocessed_gpu, total_words=total_words, epochs=5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nltk.download()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(model3.wv.key_to_index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sims = model3.wv.most_similar('lots',topn=10) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sims","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}